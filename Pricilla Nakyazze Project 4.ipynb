{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a855cb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.sparse import csr_matrix \n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7485793c",
   "metadata": {},
   "source": [
    "This Data is from 24,938 users who have rated between 15 and 35 jokes, a matrix with dimensions 24,938 X 101\n",
    "\n",
    "rows = 24,983 users columns = 100 jokes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d441ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\pricc\\OneDrive\\Desktop\\jester-data-1.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e9813b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c6a4145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (24983, 101) (24982 users × 101 jokes)\n"
     ]
    }
   ],
   "source": [
    "joke_matrix = df.to_numpy()\n",
    "print(\"Shape:\", df.shape, \"(24982 users × 101 jokes)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e4ed97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Assign column names: first column is 'ratingCount', then joke_1 to joke_100\n",
    "df.columns = ['ratingCount'] + [f'joke_{i}' for i in range(1, 101)]\n",
    "\n",
    "#Step 4: Remove 'ratingCount' column\n",
    "ratings = df.drop(columns=['ratingCount'])\n",
    "\n",
    "#Step 5: Replace 99 (unrated) with NaN\n",
    "ratings.replace(99, np.nan, inplace=True)\n",
    "\n",
    "#Step 6: Select first 5000 users\n",
    "ratings = ratings.iloc[:5000]\n",
    "\n",
    "#Step 7: Convert to NumPy matrix (if needed)\n",
    "ratings_matrix = ratings.to_numpy()\n",
    "\n",
    "#step 8: Convert to sparse matrix (CSR format)¶\n",
    "ratings_sparse = csr_matrix(np.nan_to_num(ratings_matrix, nan=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e371fc98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Jester ratings DataFrame (first 5 rows):\n",
      "   joke_1  joke_2  joke_3  joke_4  joke_5  joke_6  joke_7  joke_8  joke_9  \\\n",
      "0   -7.82    8.79   -9.66   -8.16   -7.52   -8.50   -9.85    4.17   -8.98   \n",
      "1    4.08   -0.29    6.36    4.37   -2.38   -9.66   -0.73   -5.34    8.88   \n",
      "2     NaN     NaN     NaN     NaN    9.03    9.27    9.03    9.27     NaN   \n",
      "3     NaN    8.35     NaN     NaN    1.80    8.16   -2.82    6.21     NaN   \n",
      "4    8.50    4.61   -4.17   -5.39    1.36    1.60    7.04    4.61   -0.44   \n",
      "\n",
      "   joke_10  ...  joke_91  joke_92  joke_93  joke_94  joke_95  joke_96  \\\n",
      "0    -4.76  ...     2.82      NaN      NaN      NaN      NaN      NaN   \n",
      "1     9.22  ...     2.82    -4.95    -0.29     7.86    -0.19    -2.14   \n",
      "2      NaN  ...      NaN      NaN      NaN     9.08      NaN      NaN   \n",
      "3     1.84  ...      NaN      NaN      NaN     0.53      NaN      NaN   \n",
      "4     5.73  ...     5.19     5.58     4.27     5.19     5.73     1.55   \n",
      "\n",
      "   joke_97  joke_98  joke_99  joke_100  \n",
      "0    -5.63      NaN      NaN       NaN  \n",
      "1     3.06     0.34    -4.32      1.07  \n",
      "2      NaN      NaN      NaN       NaN  \n",
      "3      NaN      NaN      NaN       NaN  \n",
      "4     3.11     6.55     1.80      1.60  \n",
      "\n",
      "[5 rows x 100 columns]\n",
      "\n",
      "============================================================\n",
      "\n",
      "Converted Jester Ratings Matrix:\n",
      "Shape: (5000, 100) (users × jokes)\n",
      "[[-7.82  8.79 -9.66 ...   nan   nan   nan]\n",
      " [ 4.08 -0.29  6.36 ...  0.34 -4.32  1.07]\n",
      " [  nan   nan   nan ...   nan   nan   nan]\n",
      " ...\n",
      " [-0.68 -2.48 -3.4  ...   nan   nan   nan]\n",
      " [ 1.02 -3.16  3.16 ... -0.68 -6.6  -1.75]\n",
      " [ 3.54  2.82 -2.14 ...  1.31  0.87  5.29]]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Show original DataFrame we are converting\n",
    "print(\"Original Jester ratings DataFrame (first 5 rows):\")\n",
    "print(ratings.head())\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Step 2: Convert to matrix\n",
    "ratings_matrix = ratings.to_numpy()\n",
    "\n",
    "# Step 3: Print matrix summary\n",
    "print(\"Converted Jester Ratings Matrix:\")\n",
    "print(\"Shape:\", ratings.shape, \"(users × jokes)\")\n",
    "print(ratings_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc8abeab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     74\n",
      "1    100\n",
      "2     49\n",
      "3     48\n",
      "4     91\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count number of non-NaN ratings per user (row)\n",
    "joke_counts = ratings.notna().sum(axis=1)\n",
    "\n",
    "# Display first few counts\n",
    "print(joke_counts.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fb46145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best joke is joke_89 with an average rating of 4.01\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Calculate average rating for each joke (ignore NaNs)\n",
    "joke_means = ratings.mean(axis=0)\n",
    "\n",
    "# Step 2: Find index of best joke (max average rating)\n",
    "best_joke_index = joke_means.idxmax()\n",
    "\n",
    "# Step 3: Get the average rating of that joke\n",
    "best_joke_rating = joke_means.max()\n",
    "\n",
    "print(f\"Best joke is {best_joke_index} with an average rating of {best_joke_rating:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6214ea49",
   "metadata": {},
   "source": [
    "JUST FOR LAUGHS JOKE 89\n",
    "\n",
    "A radio conversation of a US naval ship with Canadian authorities.\n",
    "\n",
    "Americans: Please divert your course 15 degrees to the North to avoid a collision.\n",
    "\n",
    "Canadians: Recommend you divert YOUR course 15 degrees to the South to avoid a collision.\n",
    "\n",
    "Americans: This is the Captain of a US Navy ship. I say again, divert YOUR course.\n",
    "\n",
    "Canadians: No. I say again, you divert YOUR course.\n",
    "\n",
    "Americans: This is the aircraft carrier USS LINCOLN, the second largest ship in the United States' Atlantic Fleet. We are accompanied by three destroyers, three cruisers and numerous support vessels. I demand that you change your course 15 degrees north, that's ONE FIVE DEGREES NORTH, or counter-measures will be undertaken to ensure the safety of this ship.\n",
    "\n",
    "Canadians: This is a lighthouse.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a16875ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommended joke indices for user 10: [49 34 28 26 35]\n",
      "Novelty: 0.0522\n",
      "Diversity: 0.5257\n",
      "Serendipity: 0.7638\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Use your cleaned ratings DataFrame (5000 × 100, NaNs where no rating)\n",
    "# Fill NaNs with 0s for SVD input\n",
    "ratings_matrix = ratings.fillna(0).to_numpy()\n",
    "\n",
    "# Step 2: Perform SVD\n",
    "svd = TruncatedSVD(n_components=20, random_state=42)\n",
    "user_factors = svd.fit_transform(ratings_matrix)\n",
    "item_factors = svd.components_.T  # shape: (100 jokes × 20 latent features)\n",
    "\n",
    "# Step 3: Choose a user (e.g., user index 10)\n",
    "user_idx = 10\n",
    "user_vector = user_factors[user_idx]\n",
    "\n",
    "# Step 4: Compute scores and get top recommendations\n",
    "scores = np.dot(item_factors, user_vector)\n",
    "top_items = np.argsort(-scores)[:5]\n",
    "\n",
    "# Step 5: Novelty — penalize popular jokes\n",
    "item_popularity = np.sum(ratings_matrix > 0, axis=0)\n",
    "item_popularity = item_popularity / item_popularity.max()\n",
    "novelty = np.mean([1 - item_popularity[i] for i in top_items])\n",
    "\n",
    "# Step 6: Diversity — average pairwise dissimilarity among recommended items\n",
    "item_vecs = item_factors[top_items]\n",
    "sim_matrix = cosine_similarity(item_vecs)\n",
    "upper_triangle = sim_matrix[np.triu_indices(len(top_items), k=1)]\n",
    "diversity = 1 - np.mean(upper_triangle)\n",
    "\n",
    "# Step 7: Serendipity — dissimilarity from user's past highly rated jokes\n",
    "liked_items = np.where(ratings_matrix[user_idx] >= 4)[0]\n",
    "liked_vecs = item_factors[liked_items]\n",
    "serendipity_scores = []\n",
    "\n",
    "for i in top_items:\n",
    "    rec_vec = item_factors[i].reshape(1, -1)\n",
    "    if liked_vecs.shape[0] > 0:\n",
    "        sim = cosine_similarity(rec_vec, liked_vecs)\n",
    "        serendipity_scores.append(1 - np.mean(sim))\n",
    "\n",
    "serendipity = np.mean(serendipity_scores)\n",
    "\n",
    "# Step 8: Print results\n",
    "print(f\"Top recommended joke indices for user {user_idx}: {top_items}\")\n",
    "print(f\"Novelty: {novelty:.4f}\")\n",
    "print(f\"Diversity: {diversity:.4f}\")\n",
    "print(f\"Serendipity: {serendipity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652c01db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Global Baseline Recommender Results:\n",
      "RMSE: 4.329\n",
      "MAE: 3.453\n"
     ]
    }
   ],
   "source": [
    "ratings.columns = ['ratingCount'] + [f'joke_{i}' for i in range(1, 100)]\n",
    "ratings = ratings.drop(columns=['ratingCount'])\n",
    "ratings.replace(99, np.nan, inplace=True)\n",
    "ratings = ratings.iloc[:5000]  # first 5000 users\n",
    "\n",
    "# Step 2: Convert to long format\n",
    "ratings_long = ratings.reset_index().melt(id_vars='index', var_name='item_id', value_name='rating')\n",
    "ratings_long.columns = ['user_id', 'item_id', 'rating']\n",
    "ratings_long.dropna(inplace=True)\n",
    "ratings_long['user_id'] = ratings_long['user_id'].apply(lambda x: f'u{x}')\n",
    "ratings_long['item_id'] = ratings_long['item_id'].apply(lambda x: f'j{int(x.split(\"_\")[1])}')\n",
    "\n",
    "# Step 3: Faster Global Baseline Recommender\n",
    "class FastGlobalBaseline:\n",
    "    def __init__(self, reg_user=5.0, reg_item=5.0):\n",
    "        self.reg_user = reg_user\n",
    "        self.reg_item = reg_item\n",
    "\n",
    "    def fit(self, df):\n",
    "        self.mu = df['rating'].mean()\n",
    "\n",
    "        # Compute user bias\n",
    "        user_sum = df.groupby('user_id')['rating'].sum()\n",
    "        user_count = df.groupby('user_id')['rating'].count()\n",
    "        self.bu = ((user_sum - user_count * self.mu) / (user_count + self.reg_user)).to_dict()\n",
    "\n",
    "        # Adjusted ratings for item bias\n",
    "        df['adj_rating'] = df.apply(lambda row: row['rating'] - self.mu - self.bu.get(row['user_id'], 0), axis=1)\n",
    "        item_sum = df.groupby('item_id')['adj_rating'].sum()\n",
    "        item_count = df.groupby('item_id')['adj_rating'].count()\n",
    "        self.bi = (item_sum / (item_count + self.reg_item)).to_dict()\n",
    "\n",
    "    def predict(self, user_id, item_id):\n",
    "        return max(-10, min(10, self.mu + self.bu.get(user_id, 0) + self.bi.get(item_id, 0)))\n",
    "\n",
    "    def predict_batch(self, user_item_pairs):\n",
    "        return [self.predict(u, i) for u, i in user_item_pairs]\n",
    "\n",
    "# Step 4: Train/test split and evaluate\n",
    "train_data, test_data = train_test_split(ratings_long, test_size=0.2, random_state=42)\n",
    "\n",
    "model = FastGlobalBaseline()\n",
    "model.fit(train_data)\n",
    "\n",
    "# Predict\n",
    "test_data['predicted'] = model.predict_batch(list(zip(test_data['user_id'], test_data['item_id'])))\n",
    "\n",
    "# Evaluate\n",
    "rmse = np.sqrt(mean_squared_error(test_data['rating'], test_data['predicted']))\n",
    "mae = np.mean(np.abs(test_data['rating'] - test_data['predicted']))\n",
    "\n",
    "print(f\"Global Baseline Recommender Results:\")\n",
    "print(f\"RMSE: {rmse:.3f}\")\n",
    "print(f\"MAE: {mae:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1bb4cd65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model   RMSE     MSE    MAE\n",
      "0   SVD  3.214  10.328  2.421\n",
      "1  UBCF  3.885  15.093  3.065\n",
      "2  IBCF  4.254  18.096  3.398\n"
     ]
    }
   ],
   "source": [
    "# Fill NaNs temporarily with zeros for SVD input\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "ratings_filled = pd.DataFrame(imputer.fit_transform(ratings), columns=ratings.columns)\n",
    "\n",
    "# Mask of known ratings\n",
    "mask = ~ratings.isna()\n",
    "true_values = ratings[mask]\n",
    "\n",
    "def evaluate(preds, truth_mask):\n",
    "    y_true = truth_mask.values.flatten()\n",
    "    y_pred = preds.values.flatten()\n",
    "    mask_flat = ~np.isnan(y_true)\n",
    "    return {\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(y_true[mask_flat], y_pred[mask_flat])),\n",
    "        \"MSE\": mean_squared_error(y_true[mask_flat], y_pred[mask_flat]),\n",
    "        \"MAE\": mean_absolute_error(y_true[mask_flat], y_pred[mask_flat])\n",
    "    }\n",
    "\n",
    "# --- SVD (no change) ---\n",
    "svd = TruncatedSVD(n_components=20, random_state=42)\n",
    "svd_user_factors = svd.fit_transform(ratings_filled)\n",
    "svd_item_factors = svd.components_.T\n",
    "svd_preds = pd.DataFrame(np.dot(svd_user_factors, svd_item_factors.T), columns=ratings.columns)\n",
    "svd_metrics = evaluate(svd_preds, true_values)\n",
    "\n",
    "# --- UBCF with user mean normalization ---\n",
    "user_means = ratings.mean(axis=1)\n",
    "ratings_centered = ratings.subtract(user_means, axis=0).fillna(0)\n",
    "\n",
    "user_sim = cosine_similarity(ratings_centered)\n",
    "np.fill_diagonal(user_sim, 0)\n",
    "\n",
    "# Weighted sum predictions\n",
    "weighted_sum = np.dot(user_sim, ratings_centered)\n",
    "sim_sums = np.abs(user_sim).sum(axis=1)[:, None]\n",
    "sim_sums[sim_sums == 0] = 1e-8  # avoid div by zero\n",
    "\n",
    "ubcf_preds_centered = weighted_sum / sim_sums\n",
    "# Add back user means\n",
    "ubcf_preds = pd.DataFrame(ubcf_preds_centered, columns=ratings.columns).add(user_means, axis=0)\n",
    "\n",
    "ubcf_metrics = evaluate(ubcf_preds, true_values)\n",
    "\n",
    "# --- IBCF with item mean normalization ---\n",
    "item_means = ratings.mean(axis=0)\n",
    "ratings_centered_item = ratings.subtract(item_means, axis=1).fillna(0)\n",
    "\n",
    "item_sim = cosine_similarity(ratings_centered_item.T)\n",
    "np.fill_diagonal(item_sim, 0)\n",
    "\n",
    "weighted_sum_item = np.dot(ratings_centered_item, item_sim)\n",
    "sim_sums_item = np.abs(item_sim).sum(axis=1)\n",
    "sim_sums_item[sim_sums_item == 0] = 1e-8\n",
    "\n",
    "ibcf_preds_centered = weighted_sum_item / sim_sums_item\n",
    "ibcf_preds = pd.DataFrame(ibcf_preds_centered, columns=ratings.columns).add(item_means, axis=1)\n",
    "\n",
    "ibcf_metrics = evaluate(ibcf_preds, true_values)\n",
    "# --- Results ---\n",
    "results = pd.DataFrame([\n",
    "    {\"Model\": \"SVD\", **svd_metrics},\n",
    "    {\"Model\": \"UBCF\", **ubcf_metrics},\n",
    "    {\"Model\": \"IBCF\", **ibcf_metrics}\n",
    "])\n",
    "\n",
    "print(results.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "25ee8974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD run fold/sample [model time/prediction time]\n",
      " 1  [0.033sec/0.000sec]\n",
      "UBCF run fold/sample [model time/prediction time]\n",
      " 1  [0.097sec/0.131sec]\n",
      "IBCF run fold/sample [model time/prediction time]\n",
      " 1  [0.010sec/0.004sec]\n"
     ]
    }
   ],
   "source": [
    "# --- SVD ---\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "ratings_filled = pd.DataFrame(imputer.fit_transform(ratings), columns=ratings.columns)\n",
    "\n",
    "start_model = time.time()\n",
    "svd = TruncatedSVD(n_components=20, random_state=42)\n",
    "user_factors = svd.fit_transform(ratings_filled)\n",
    "item_factors = svd.components_.T\n",
    "end_model = time.time()\n",
    "\n",
    "start_pred = time.time()\n",
    "svd_preds = pd.DataFrame(np.dot(user_factors, item_factors.T), columns=ratings.columns)\n",
    "end_pred = time.time()\n",
    "\n",
    "print(f\"SVD run fold/sample [model time/prediction time]\\n 1  [{end_model - start_model:.3f}sec/{end_pred - start_pred:.3f}sec]\")\n",
    "\n",
    "# --- UBCF ---\n",
    "user_means = ratings.mean(axis=1)\n",
    "ratings_centered = ratings.subtract(user_means, axis=0).fillna(0)\n",
    "\n",
    "start_model = time.time()\n",
    "user_sim = cosine_similarity(ratings_centered)\n",
    "np.fill_diagonal(user_sim, 0)\n",
    "end_model = time.time()\n",
    "\n",
    "start_pred = time.time()\n",
    "weighted_sum = np.dot(user_sim, ratings_centered)\n",
    "sim_sums = np.abs(user_sim).sum(axis=1)[:, None]\n",
    "sim_sums[sim_sums == 0] = 1e-8\n",
    "ubcf_preds_centered = weighted_sum / sim_sums\n",
    "ubcf_preds = pd.DataFrame(ubcf_preds_centered, columns=ratings.columns).add(user_means, axis=0)\n",
    "end_pred = time.time()\n",
    "\n",
    "print(f\"UBCF run fold/sample [model time/prediction time]\\n 1  [{end_model - start_model:.3f}sec/{end_pred - start_pred:.3f}sec]\")\n",
    "\n",
    "# --- IBCF ---\n",
    "item_means = ratings.mean(axis=0)\n",
    "ratings_centered_item = ratings.subtract(item_means, axis=1).fillna(0)\n",
    "\n",
    "start_model = time.time()\n",
    "item_sim = cosine_similarity(ratings_centered_item.T)\n",
    "np.fill_diagonal(item_sim, 0)\n",
    "end_model = time.time()\n",
    "\n",
    "start_pred = time.time()\n",
    "weighted_sum_item = np.dot(ratings_centered_item, item_sim)\n",
    "sim_sums_item = np.abs(item_sim).sum(axis=1)\n",
    "sim_sums_item[sim_sums_item == 0] = 1e-8\n",
    "ibcf_preds_centered = weighted_sum_item / sim_sums_item\n",
    "ibcf_preds = pd.DataFrame(ibcf_preds_centered, columns=ratings.columns).add(item_means, axis=1)\n",
    "end_pred = time.time()\n",
    "\n",
    "print(f\"IBCF run fold/sample [model time/prediction time]\\n 1  [{end_model - start_model:.3f}sec/{end_pred - start_pred:.3f}sec]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10061d6",
   "metadata": {},
   "source": [
    "Increase Serendipity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f6641f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model   RMSE     MSE    MAE\n",
      "0  UBCF2  3.880  15.058  3.061\n",
      "1   SVD2  3.206  10.279  2.418\n",
      "2  IBCF2  4.251  18.069  3.395\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def evaluate(preds, truth_mask):\n",
    "    y_true = truth_mask.values.flatten()\n",
    "    y_pred = preds.values.flatten()\n",
    "    mask_flat = ~np.isnan(y_true)\n",
    "    return {\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(y_true[mask_flat], y_pred[mask_flat])),\n",
    "        \"MSE\": mean_squared_error(y_true[mask_flat], y_pred[mask_flat]),\n",
    "        \"MAE\": mean_absolute_error(y_true[mask_flat], y_pred[mask_flat])\n",
    "    }\n",
    "\n",
    "# Use same ratings DataFrame from earlier\n",
    "true_values = ratings.copy()\n",
    "true_values[true_values == 99] = np.nan\n",
    "\n",
    "# --- SVD2 (base) ---\n",
    "svd2_metrics = evaluate(svd_preds, true_values)\n",
    "\n",
    "# --- UBCF2 ---\n",
    "ubcf2_metrics = evaluate(ubcf_preds, true_values)\n",
    "\n",
    "# --- IBCF2 ---\n",
    "ibcf2_metrics = evaluate(ibcf_preds, true_values)\n",
    "\n",
    "# --- Combine ---\n",
    "results_serendipity = pd.DataFrame([\n",
    "    {\"Model\": \"UBCF2\", **ubcf2_metrics},\n",
    "    {\"Model\": \"SVD2\", **svd2_metrics},\n",
    "    {\"Model\": \"IBCF2\", **ibcf2_metrics}\n",
    "])\n",
    "print(results_serendipity.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b9fafba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Precision@5\n",
      "UBCF2        0.632\n",
      "SVD2         0.621\n",
      "IBCF2        0.409\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def precision_at_k(preds, truth, k=5, threshold=5.0):\n",
    "    precisions = []\n",
    "    \n",
    "    for user_idx in range(len(truth)):\n",
    "        true_ratings = truth.iloc[user_idx]\n",
    "        pred_ratings = preds.iloc[user_idx]\n",
    "\n",
    "        # Only consider items the user has rated\n",
    "        known_items = true_ratings[~true_ratings.isna()]\n",
    "\n",
    "        # Get top-K predictions for those known items\n",
    "        top_k_items = pred_ratings[known_items.index].sort_values(ascending=False).head(k)\n",
    "\n",
    "        # Count how many of the top K were actually relevant\n",
    "        actual_relevant = true_ratings[top_k_items.index] >= threshold\n",
    "        precision = actual_relevant.sum() / k\n",
    "        precisions.append(precision)\n",
    "\n",
    "    return np.mean(precisions)\n",
    "p_at_5 = {\n",
    "    \"UBCF2\": precision_at_k(ubcf_preds, true_values, k=5),\n",
    "    \"SVD2\": precision_at_k(svd_preds, true_values, k=5),\n",
    "    \"IBCF2\": precision_at_k(ibcf_preds, true_values, k=5)\n",
    "}\n",
    "print(pd.DataFrame.from_dict(p_at_5, orient='index', columns=['Precision@5']).round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc24fc8",
   "metadata": {},
   "source": [
    "Data source\n",
    "\n",
    "Eigentaste: A Constant Time Collaborative Filtering Algorithm. Ken Goldberg, Theresa Roeder, Dhruv Gupta, and Chris Perkins. Information Retrieval, 4(2), 133-151. July 2001. u."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf38f68d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
