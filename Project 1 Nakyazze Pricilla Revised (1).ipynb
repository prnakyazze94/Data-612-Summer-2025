{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6df79b27-7434-4e15-ae33-dea230006e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This system recommends restocking of fruits based on a user-item matrix representing\n",
    "# fruit ratings given by users (on different days of the week) to items (the fruits). \n",
    "# Since not every item has a rating for everyday, we build a recommendation system to\n",
    "# predict the missing values \n",
    "# — and from there, we can recommend items.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "659f2eb0-5d44-401f-8ee2-1003f8733779",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a user-item matrix with missing data\n",
    "#This DataFrame represents our core ratings matrix — users (days of week)\n",
    "# rate items (fruits), with missing values that the recommender system will predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "11c1fee3-3ef1-4ea2-bada-26968ba8c8a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bananas</th>\n",
       "      <th>Apples</th>\n",
       "      <th>Watermelon</th>\n",
       "      <th>PassionFruit</th>\n",
       "      <th>SugarCane</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Monday</th>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tuesday</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wednesday</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thursday</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Friday</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Saturday</th>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sunday</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           bananas  Apples  Watermelon  PassionFruit  SugarCane\n",
       "Monday         3.0     7.0         NaN           6.0        6.0\n",
       "Tuesday        4.0     2.0         5.0           NaN        8.0\n",
       "Wednesday      3.0     NaN         3.0           5.0        NaN\n",
       "Thursday       NaN     5.0         NaN           NaN        5.0\n",
       "Friday         5.0     4.0         5.0           9.0        7.0\n",
       "Saturday       9.0     8.0         8.0           9.0        4.0\n",
       "Sunday         NaN     4.0         3.0           2.0        NaN"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = {\n",
    "    \"bananas\":       [3, 4, 3, np.nan, 5, 9, np.nan],\n",
    "    \"Apples\":        [7, 2, np.nan, 5, 4, 8, 4],\n",
    "    \"Watermelon\":    [np.nan, 5, 3, np.nan, 5, 8, 3],\n",
    "    \"PassionFruit\":  [6, np.nan, 5, np.nan, 9, 9, 2],\n",
    "    \"SugarCane\":     [6, 8, np.nan, 5, 7, 4, np.nan]\n",
    "}\n",
    "index = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "df = pd.DataFrame(data, index=index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b069aba4-7721-4759-9363-b5343b9db55d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "82520bbb-6879-47ed-987e-fce185c783e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Break your ratings into separate training and test datasets.\n",
    "# Select non-missing entries and randomly hold out 20% for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "707d623f-3c69-4e3a-8d4d-cac2dc24f6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-missing values\n",
    "non_missing_positions = [(i, j) for i in range(df.shape[0]) for j in range(df.shape[1]) if not pd.isna(df.iat[i, j])]\n",
    "\n",
    "# 20% for test set\n",
    "# This allows us to evaluate how well our model predicts unseen data\n",
    "np.random.seed(42)\n",
    "test_sample_size = int(0.2 * len(non_missing_positions))\n",
    "test_indices = np.random.choice(len(non_missing_positions), size=test_sample_size, replace=False)\n",
    "\n",
    "#  dataframes\n",
    "train_df = df.copy()\n",
    "test_df = df.copy()\n",
    "\n",
    "# Populate test_df with only the held-out values, and mask them in train_df\n",
    "for idx in range(len(non_missing_positions)):\n",
    "    i, j = non_missing_positions[idx]\n",
    "    if idx in test_indices:\n",
    "        train_df.iat[i, j] = np.nan  # remove from train\n",
    "    else:\n",
    "        test_df.iat[i, j] = np.nan  # remove from test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d4b113d8-8950-4163-9de4-1846aea3c980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original ratings: 26\n",
      "Train ratings:    21\n",
      "Test ratings:     5\n"
     ]
    }
   ],
   "source": [
    "print(\"Original ratings:\", df.count().sum())\n",
    "print(\"Train ratings:   \", train_df.count().sum())\n",
    "print(\"Test ratings:    \", test_df.count().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4008bf24-7b15-4160-8631-9bfb1bb8c346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = values that were removed from df to create train_df\n",
    "test_df = df.copy()\n",
    "\n",
    "# For all entries that are NOT missing in df but ARE missing in train_df,\n",
    "# keep the value; otherwise, set to NaN\n",
    "for i in range(df.shape[0]):\n",
    "    for j in range(df.shape[1]):\n",
    "        if pd.notna(df.iat[i, j]) and pd.isna(train_df.iat[i, j]):\n",
    "            # Keep it in test_df\n",
    "            continue\n",
    "        else:\n",
    "            # Set to NaN (either was missing originally or still present in train_df)\n",
    "            test_df.iat[i, j] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ab05b00c-1863-4558-a67f-58b24a195c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           bananas  Apples  Watermelon  PassionFruit  SugarCane\n",
      "Monday         NaN     7.0         NaN           6.0        6.0\n",
      "Tuesday        4.0     2.0         5.0           NaN        8.0\n",
      "Wednesday      NaN     NaN         3.0           5.0        NaN\n",
      "Thursday       NaN     NaN         NaN           NaN        5.0\n",
      "Friday         5.0     4.0         5.0           NaN        7.0\n",
      "Saturday       9.0     8.0         8.0           9.0        4.0\n",
      "Sunday         NaN     4.0         NaN           2.0        NaN\n"
     ]
    }
   ],
   "source": [
    "print(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fe12d902-893a-42a8-8c62-0ff6ca2eca12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           bananas  Apples  Watermelon  PassionFruit  SugarCane\n",
      "Monday         3.0     NaN         NaN           NaN        NaN\n",
      "Tuesday        NaN     NaN         NaN           NaN        NaN\n",
      "Wednesday      3.0     NaN         NaN           NaN        NaN\n",
      "Thursday       NaN     5.0         NaN           NaN        NaN\n",
      "Friday         NaN     NaN         NaN           9.0        NaN\n",
      "Saturday       NaN     NaN         NaN           NaN        NaN\n",
      "Sunday         NaN     NaN         3.0           NaN        NaN\n"
     ]
    }
   ],
   "source": [
    "print(test_df)\n",
    "#this helps us compare predicted vs. actual values without including original NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b48c48f5-892d-47a1-8fc7-95cda6d51d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monday rated bananas = 3.0\n",
      "Wednesday rated bananas = 3.0\n",
      "Thursday rated Apples = 5.0\n",
      "Friday rated PassionFruit = 9.0\n",
      "Sunday rated Watermelon = 3.0\n"
     ]
    }
   ],
   "source": [
    "test_entries = [(index, col, test_df.loc[index, col])\n",
    "                for index in test_df.index\n",
    "                for col in test_df.columns\n",
    "                if not pd.isna(test_df.loc[index, col])]\n",
    "\n",
    "# Example output\n",
    "for user, item, rating in test_entries:\n",
    "    print(f\"{user} rated {item} = {rating}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "bd7edae5-692e-4d62-bc6b-de653e927a48",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Calculate global average rating.\n",
    "#The global mean serves as a basic predictor to fill in missing values,\n",
    "# and it's also the foundation for calculating user/item biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "018330fc-5dcd-4958-b001-dc356d0a9242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global average rating: 5.52\n"
     ]
    }
   ],
   "source": [
    "global_mean = train_df.stack().mean()\n",
    "print(f\"Global average rating: {global_mean:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8d57da61-1256-42c3-909b-409784e51ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate raw average predictions (fill NaNs with global mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "35e8f6c6-8713-43a5-981d-0788861a6887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           bananas   Apples  Watermelon  PassionFruit  SugarCane\n",
      "Monday     5.52381  7.00000     5.52381       6.00000    6.00000\n",
      "Tuesday    4.00000  2.00000     5.00000       5.52381    8.00000\n",
      "Wednesday  5.52381  5.52381     3.00000       5.00000    5.52381\n",
      "Thursday   5.52381  5.52381     5.52381       5.52381    5.00000\n",
      "Friday     5.00000  4.00000     5.00000       5.52381    7.00000\n",
      "Saturday   9.00000  8.00000     8.00000       9.00000    4.00000\n",
      "Sunday     5.52381  4.00000     5.52381       2.00000    5.52381\n"
     ]
    }
   ],
   "source": [
    "raw_avg_pred = train_df.copy()\n",
    "raw_avg_pred = raw_avg_pred.fillna(global_mean)\n",
    "print(raw_avg_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0a53b479-4139-438d-b2fd-2e933e0e21f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_avg_pred = raw_avg_pred.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "da464f1d-3db1-4636-9fa0-f2a6e9a41994",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the raw average (mean) rating for every user-item combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "139f8b42-6d00-4a4c-9d1b-d974dfd8c834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monday: 6.33\n",
      "Tuesday: 4.75\n",
      "Wednesday: 4.00\n",
      "Thursday: 5.00\n",
      "Friday: 5.25\n",
      "Saturday: 7.60\n",
      "Sunday: 3.00\n"
     ]
    }
   ],
   "source": [
    "# Compute the raw average for each user (i.e., each row in train_df)\n",
    "user_raw_averages = train_df.mean(axis=1, skipna=True)\n",
    "\n",
    "# Display the results\n",
    "for user, avg in zip(train_df.index, user_raw_averages):\n",
    "    print(f\"{user}: {avg:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f4a2b1e6-dd01-462d-b451-63b111c86bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monday       0.809524\n",
      "Tuesday     -0.773810\n",
      "Wednesday   -1.523810\n",
      "Thursday    -0.523810\n",
      "Friday      -0.273810\n",
      "Saturday     2.076190\n",
      "Sunday      -2.523810\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#calculate the bias for each user and each item\n",
    "# User bias shows if a user tends to rate higher/lower than average;\n",
    "# item bias shows if an item tends to receive higher/lower ratings.\n",
    "# These help personalize baseline predictions beyond global mean.\n",
    "\n",
    "user_bias = train_df.sub(global_mean, axis=0).mean(axis=1, skipna=True)\n",
    "print(user_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "57e61261-3ce2-40b4-91c8-969ac0004bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bananas         0.133333\n",
      "Apples         -0.386667\n",
      "Watermelon     -0.150000\n",
      "PassionFruit    0.266667\n",
      "SugarCane       0.213333\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Subtract user bias from ratings to isolate item bias\n",
    "# item bias shows if an item tends to receive higher/lower ratings.\n",
    "# These help personalize baseline predictions beyond global mean.\n",
    "adjusted_for_user = train_df.copy()\n",
    "for user in train_df.index:\n",
    "    adjusted_for_user.loc[user] = train_df.loc[user] - user_bias[user]\n",
    "\n",
    "item_bias = adjusted_for_user.sub(global_mean, axis=0).mean(skipna=True)\n",
    "print(item_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "10195c41-9989-41c5-a14b-b4f6426870a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the baseline predictors for every user-item combination.\n",
    "#  The baseline predictor adjusts the global mean using user and item biases.\n",
    "# It gives a more personalized prediction without complex algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e736b1f5-75b2-48ee-836f-e0da8845b743",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_pred = pd.DataFrame(index=train_df.index, columns=train_df.columns)\n",
    "\n",
    "for user in train_df.index:\n",
    "    for item in train_df.columns:\n",
    "        bu = user_bias.get(user, 0)\n",
    "        bi = item_bias.get(item, 0)\n",
    "        baseline_pred.loc[user, item] = global_mean + bu + bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "59c4bbcc-df31-49ce-83ff-9bb479a98b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Recommendation per User:\n",
      "  Monday: Recommend 'bananas' with predicted rating 6.47\n",
      "  Tuesday: Recommend 'PassionFruit' with predicted rating 5.02\n",
      "  Wednesday: Recommend 'SugarCane' with predicted rating 4.21\n",
      "  Thursday: Recommend 'PassionFruit' with predicted rating 5.27\n",
      "  Friday: Recommend 'PassionFruit' with predicted rating 5.52\n",
      "  Sunday: Recommend 'SugarCane' with predicted rating 3.21\n"
     ]
    }
   ],
   "source": [
    "# Ensure numeric values\n",
    "baseline_pred = baseline_pred.astype(float)\n",
    "\n",
    "# Generate top recommendation per user\n",
    "# This simulates what the system would recommend in practice.\n",
    "recommendations = {}\n",
    "\n",
    "for user in baseline_pred.index:\n",
    "    # Identify which items were missing in train_df\n",
    "    missing_items = train_df.loc[user][train_df.loc[user].isna()].index.tolist()\n",
    "    \n",
    "    if missing_items:\n",
    "        # Slice the predicted ratings for missing items only\n",
    "        predicted_ratings = baseline_pred.loc[user, missing_items]\n",
    "        \n",
    "        # Get the item with the highest predicted rating\n",
    "        recommended_item = predicted_ratings.idxmax()\n",
    "        predicted_rating = predicted_ratings.max()\n",
    "        \n",
    "        recommendations[user] = (recommended_item, predicted_rating)\n",
    "\n",
    "# Display recommendations\n",
    "print(\"Top Recommendation per User:\")\n",
    "for user, (item, rating) in recommendations.items():\n",
    "    print(f\"  {user}: Recommend '{item}' with predicted rating {rating:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b1bde44e-1d5c-48a4-a8b8-badc148a8310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           bananas  Apples  Watermelon  PassionFruit  SugarCane\n",
      "Monday        6.47    5.95        6.18          6.60       6.55\n",
      "Tuesday       4.88    4.36        4.60          5.02       4.96\n",
      "Wednesday     4.13    3.61        3.85          4.27       4.21\n",
      "Thursday      5.13    4.61        4.85          5.27       5.21\n",
      "Friday        5.38    4.86        5.10          5.52       5.46\n"
     ]
    }
   ],
   "source": [
    "baseline_pred = baseline_pred.astype(float)\n",
    "print(baseline_pred.round(2).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9ade6b05-ae5a-47b9-a96f-b64ad87831a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_avg = train_df.mean(axis=1, skipna=True)\n",
    "user_avg = user_avg.fillna(global_mean)  # Replace NaN user averages with global mean\n",
    "\n",
    "item_avg = train_df.mean(axis=0, skipna=True)\n",
    "item_avg = item_avg.fillna(global_mean) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "8d627dd4-28d4-47cb-accd-2ac97bfffe3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monday       6.333333\n",
      "Tuesday      4.750000\n",
      "Wednesday    4.000000\n",
      "Thursday     5.000000\n",
      "Friday       5.250000\n",
      "Saturday     7.600000\n",
      "Sunday       3.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(user_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d023fae0-084d-43c5-9b43-933423d740ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSE Calculate the RMSE for raw average for both your training data and your test data.\n",
    "#RMSE measures how close our predicted ratings are to the actual ones.\n",
    "# Lower RMSE indicates better performance of the recommender system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3bb594bc-cce9-41fb-92b4-850e6079583e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rmse(pred_df, actual_df):\n",
    "    # Replace NaN with 0 in both DataFrames\n",
    "    pred_df = pred_df.fillna(0)\n",
    "    actual_df = actual_df.fillna(0)\n",
    "\n",
    "    pred_vals = pred_df.values.flatten()\n",
    "    actual_vals = actual_df.values.flatten()\n",
    "\n",
    "    num_compared = len(actual_vals)\n",
    "    print(f\"Comparing {num_compared} data points (NaNs replaced with 0).\")\n",
    "\n",
    "    return np.sqrt(np.mean((pred_vals - actual_vals) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3ec15dce-de41-415e-ab5e-986a43669d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing 35 data points (NaNs replaced with 0).\n",
      "RMSE (Raw Average) on test data: 5.441\n"
     ]
    }
   ],
   "source": [
    "rmse_raw_test = compute_rmse(raw_avg_pred, test_df)\n",
    "print(f\"RMSE (Raw Average) on test data: {rmse_raw_test:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4b069592-9db3-4bb4-a2cf-6cd03141b05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = raw_avg_pred.fillna(0)\n",
    "actual_df = train_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "fa444d51-a38d-49ab-90e0-e4b6bad97178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_rmse_no_mask(pred_df, actual_df):\n",
    "    pred_vals = pred_df.values.flatten()\n",
    "    actual_vals = actual_df.values.flatten()\n",
    "    return np.sqrt(np.mean((pred_vals - actual_vals) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c33b2c12-02e3-43ec-aa32-3ef5dfce0114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " RMSE (Raw Average) on training data [NaNs treated as 0]: 3.494\n"
     ]
    }
   ],
   "source": [
    "rmse_raw_train = compute_rmse_no_mask(pred_df, actual_df)\n",
    "print(f\" RMSE (Raw Average) on training data [NaNs treated as 0]: {rmse_raw_train:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "69549760-583c-40aa-8965-7180fb632c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using your training data, calculate the bias for each user and each item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a5a0c4f3-4050-49e4-ba7d-d679d51a290e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "temp_df = train_df.copy()\n",
    "\n",
    "for user in train_df.index:\n",
    "    temp_df.loc[user] = train_df.loc[user] - user_bias[user]\n",
    "\n",
    "# Now compute item bias from the adjusted DataFrame\n",
    "item_bias = temp_df.sub(global_mean, axis=0).mean(skipna=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8c52da2c-214d-4eef-a422-05b1c043517d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Mean: 5.524\n",
      "\n",
      "User Biases:\n",
      "Monday       0.810\n",
      "Tuesday     -0.774\n",
      "Wednesday   -1.524\n",
      "Thursday    -0.524\n",
      "Friday      -0.274\n",
      "Saturday     2.076\n",
      "Sunday      -2.524\n",
      "dtype: float64\n",
      "\n",
      "Item Biases:\n",
      "bananas         0.133\n",
      "Apples         -0.387\n",
      "Watermelon     -0.150\n",
      "PassionFruit    0.267\n",
      "SugarCane       0.213\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Global Mean:\", round(global_mean, 3))\n",
    "print(\"\\nUser Biases:\")\n",
    "print(user_bias.round(3))\n",
    "\n",
    "print(\"\\nItem Biases:\")\n",
    "print(item_bias.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "300b5733-0e7e-41ac-afd6-c35e1a2fa901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE for the baseline predictors for both your training data and your test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "57ce7df9-eb13-4865-bdc8-f1eb0cf73818",
   "metadata": {},
   "outputs": [],
   "source": [
    " # RMSE for the baseline predictors test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f2521061-1723-46f2-bbc8-fb004f1971ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " RMSE on test data: 2.263\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Collect predicted and actual ratings\n",
    "predicted_ratings = []\n",
    "actual_ratings = []\n",
    "\n",
    "for user, item, actual in test_entries:\n",
    "    pred = baseline_pred.loc[user, item]\n",
    "    predicted_ratings.append(pred)\n",
    "    actual_ratings.append(actual)\n",
    "\n",
    "# Convert to arrays\n",
    "predicted_ratings = np.array(predicted_ratings)\n",
    "actual_ratings = np.array(actual_ratings)\n",
    "\n",
    "# Compute RMSE\n",
    "rmse = np.sqrt(np.mean((predicted_ratings - actual_ratings) ** 2))\n",
    "print(f\" RMSE on test data: {rmse:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "3a942063-2c17-4b28-a2b1-45caefb9d86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## RMSE for the baseline predictors for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7d353ff1-81c3-4737-a379-9e3f11773ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " RMSE on training data: 1.447\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Extract non-NaN training entries\n",
    "train_entries = [\n",
    "    (user, item, train_df.loc[user, item])\n",
    "    for user in train_df.index\n",
    "    for item in train_df.columns\n",
    "    if not pd.isna(train_df.loc[user, item])\n",
    "]\n",
    "\n",
    "# Compare predictions to actuals\n",
    "predicted_ratings_train = []\n",
    "actual_ratings_train = []\n",
    "\n",
    "for user, item, actual in train_entries:\n",
    "    pred = baseline_pred.loc[user, item]\n",
    "    predicted_ratings_train.append(pred)\n",
    "    actual_ratings_train.append(actual)\n",
    "\n",
    "# Convert to arrays and compute RMSE\n",
    "predicted_ratings_train = np.array(predicted_ratings_train)\n",
    "actual_ratings_train = np.array(actual_ratings_train)\n",
    "\n",
    "rmse_train = np.sqrt(np.mean((predicted_ratings_train - actual_ratings_train) ** 2))\n",
    "print(f\" RMSE on training data: {rmse_train:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "eeb4c775-4a42-4d0b-9cda-1e2f2c5897e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize\n",
    "#Dataset\tRMSE (Root Mean Square Error)\n",
    "#Training Set\t 1.447\n",
    "#Test Set\t     2.263"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "21e592c0-3d68-4a3b-8ea2-8c698546a05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bias\n",
    "##User\t  Bias\t    Interpretation\n",
    "#Monday\t   +0.810\t   Rates higher than average\n",
    "##Tuesday\t–0.774\t    Rates lower than average\n",
    "#Wednesday\t–1.524\t    Rates much lower than average\n",
    "##Thursday\t–0.524\t     Slightly lower ratings\n",
    "#Friday\t    –0.274\t     Neutral/slightly low\n",
    "#Saturday\t+2.076\t     Very generous rater\n",
    "#Sunday\t    –2.524\t      Very strict/low rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6c382656-5402-4eb2-9c46-6c3861512cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#item bias\n",
    "#Item\t    Bias\t Interpretation\n",
    "#bananas\t    +0.133\t Slightly better than average\n",
    "#Apples\t    –0.387\t Rated lower than average\n",
    "#Watermelon\t–0.150\t   Slightly below average\n",
    "#PassionFruit  +0.267\tWell-liked\n",
    "#SugarCane\t +0.213\t     Also well-liked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "88743e68-c557-44d0-8272-1983cb733bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This baseline model captures trends in how users and items deviate from the average, \n",
    "#but doesn’t capture interaction effects or personalized preferences well \n",
    "##which is why RMSE is higher on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f6e725-c82c-44b3-8e4a-69b72604ef5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765dcea1-bab7-4ea0-bdff-b77182b23ee8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec1b6d4-b30b-410f-a91b-71918269d318",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-panel-2023.05-py310",
   "language": "python",
   "name": "conda-env-anaconda-panel-2023.05-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
