{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a855cb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.sparse import csr_matrix \n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025b1556",
   "metadata": {},
   "source": [
    "Pricilla Nakyazze\n",
    "\n",
    "\n",
    "\n",
    "DATA 612 Project 4  - Accuracy and Beyond\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7485793c",
   "metadata": {},
   "source": [
    "This Data is from 24,938 users who have rated between 15 and 35 jokes, a matrix with dimensions 24,938 X 101\n",
    "\n",
    "rows = 24,983 users columns = 100 jokes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9dffd6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.sparse import csr_matrix \n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7d441ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\pricc\\OneDrive\\Desktop\\jester-data-1.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6e9813b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8c6a4145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (24983, 101) (24982 users × 101 jokes)\n"
     ]
    }
   ],
   "source": [
    "joke_matrix = df.to_numpy()\n",
    "print(\"Shape:\", df.shape, \"(24982 users × 101 jokes)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8e4ed97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign column names: first column is 'ratingCount', then joke_1 to joke_100\n",
    "df.columns = ['ratingCount'] + [f'joke_{i}' for i in range(1, 101)]\n",
    "\n",
    "#Remove 'ratingCount' column\n",
    "ratings = df.drop(columns=['ratingCount'])\n",
    "\n",
    "#Replace 99 (unrated) with NaN\n",
    "ratings.replace(99, np.nan, inplace=True)\n",
    "\n",
    "#Select first 5000 users\n",
    "ratings = ratings.iloc[:5000]\n",
    "\n",
    "#Convert to NumPy matrix (if needed)\n",
    "ratings_matrix = ratings.to_numpy()\n",
    "\n",
    "# Convert to sparse matrix (CSR format)¶\n",
    "ratings_sparse = csr_matrix(np.nan_to_num(ratings_matrix, nan=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e371fc98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Jester ratings DataFrame (first 5 rows):\n",
      "   joke_1  joke_2  joke_3  joke_4  joke_5  joke_6  joke_7  joke_8  joke_9  \\\n",
      "0   -7.82    8.79   -9.66   -8.16   -7.52   -8.50   -9.85    4.17   -8.98   \n",
      "1    4.08   -0.29    6.36    4.37   -2.38   -9.66   -0.73   -5.34    8.88   \n",
      "2     NaN     NaN     NaN     NaN    9.03    9.27    9.03    9.27     NaN   \n",
      "3     NaN    8.35     NaN     NaN    1.80    8.16   -2.82    6.21     NaN   \n",
      "4    8.50    4.61   -4.17   -5.39    1.36    1.60    7.04    4.61   -0.44   \n",
      "\n",
      "   joke_10  ...  joke_91  joke_92  joke_93  joke_94  joke_95  joke_96  \\\n",
      "0    -4.76  ...     2.82      NaN      NaN      NaN      NaN      NaN   \n",
      "1     9.22  ...     2.82    -4.95    -0.29     7.86    -0.19    -2.14   \n",
      "2      NaN  ...      NaN      NaN      NaN     9.08      NaN      NaN   \n",
      "3     1.84  ...      NaN      NaN      NaN     0.53      NaN      NaN   \n",
      "4     5.73  ...     5.19     5.58     4.27     5.19     5.73     1.55   \n",
      "\n",
      "   joke_97  joke_98  joke_99  joke_100  \n",
      "0    -5.63      NaN      NaN       NaN  \n",
      "1     3.06     0.34    -4.32      1.07  \n",
      "2      NaN      NaN      NaN       NaN  \n",
      "3      NaN      NaN      NaN       NaN  \n",
      "4     3.11     6.55     1.80      1.60  \n",
      "\n",
      "[5 rows x 100 columns]\n",
      "\n",
      "============================================================\n",
      "\n",
      "Converted Jester Ratings Matrix:\n",
      "Shape: (5000, 100) (users × jokes)\n",
      "[[-7.82  8.79 -9.66 ...   nan   nan   nan]\n",
      " [ 4.08 -0.29  6.36 ...  0.34 -4.32  1.07]\n",
      " [  nan   nan   nan ...   nan   nan   nan]\n",
      " ...\n",
      " [-0.68 -2.48 -3.4  ...   nan   nan   nan]\n",
      " [ 1.02 -3.16  3.16 ... -0.68 -6.6  -1.75]\n",
      " [ 3.54  2.82 -2.14 ...  1.31  0.87  5.29]]\n"
     ]
    }
   ],
   "source": [
    "#  Show original DataFrame we are converting\n",
    "print(\"Original Jester ratings DataFrame (first 5 rows):\")\n",
    "print(ratings.head())\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Convert to matrix\n",
    "ratings_matrix = ratings.to_numpy()\n",
    "\n",
    "# Print matrix summary\n",
    "print(\"Converted Jester Ratings Matrix:\")\n",
    "print(\"Shape:\", ratings.shape, \"(users × jokes)\")\n",
    "print(ratings_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dc8abeab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     74\n",
      "1    100\n",
      "2     49\n",
      "3     48\n",
      "4     91\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count number of non-NaN ratings per user (row)\n",
    "joke_counts = ratings.notna().sum(axis=1)\n",
    "\n",
    "# Display first few counts\n",
    "print(joke_counts.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9fb46145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best joke is joke_89 with an average rating of 4.01\n"
     ]
    }
   ],
   "source": [
    "# Calculate average rating for each joke (ignore NaNs)\n",
    "joke_means = ratings.mean(axis=0)\n",
    "\n",
    "# Find index of best joke (max average rating)\n",
    "best_joke_index = joke_means.idxmax()\n",
    "\n",
    "#Get the average rating of that joke\n",
    "best_joke_rating = joke_means.max()\n",
    "\n",
    "print(f\"Best joke is {best_joke_index} with an average rating of {best_joke_rating:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6214ea49",
   "metadata": {},
   "source": [
    "JUST FOR LAUGHS JOKE 89\n",
    "\n",
    "A radio conversation of a US naval ship with Canadian authorities.\n",
    "\n",
    "Americans: Please divert your course 15 degrees to the North to avoid a collision.\n",
    "\n",
    "Canadians: Recommend you divert YOUR course 15 degrees to the South to avoid a collision.\n",
    "\n",
    "Americans: This is the Captain of a US Navy ship. I say again, divert YOUR course.\n",
    "\n",
    "Canadians: No. I say again, you divert YOUR course.\n",
    "\n",
    "Americans: This is the aircraft carrier USS LINCOLN, the second largest ship in the United States' Atlantic Fleet. We are accompanied by three destroyers, three cruisers and numerous support vessels. I demand that you change your course 15 degrees north, that's ONE FIVE DEGREES NORTH, or counter-measures will be undertaken to ensure the safety of this ship.\n",
    "\n",
    "Canadians: This is a lighthouse.\n",
    "\n",
    "===============================================================================================================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091ba89e",
   "metadata": {},
   "source": [
    "USER 10 Experiment.\n",
    "Below we find the jokes (columns) this model predicted user 10 would like the most.\n",
    "They’re ranked by predicted rating using latent features (from SVD).\n",
    "\n",
    "NOVELTY\n",
    "Novelty of 0.0522 measures how unpopular the recommendations are this might be very low because popular items tend to reduce novelty.\n",
    "\n",
    "DIVERSITY\n",
    "Diversity measures how different the recommended jokes are from each other.\n",
    "With a Score of 0.53 it means diversity is moderate.\n",
    "This can be improved by intentionally selecting items from distinct latent clusters.\n",
    "\n",
    "SERENDIPITY\n",
    "Serendipity means how surprising but still useful the recommendations are i.e., they are not too similar to what the user already liked.\n",
    "A serendipity score of 0.76 is high this implies new but relevant jokes that are not too similar to user's history ar recommended.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a16875ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommended joke indices for user 10: [49 34 28 26 35]\n",
      "Novelty: 0.0522\n",
      "Diversity: 0.5257\n",
      "Serendipity: 0.7638\n"
     ]
    }
   ],
   "source": [
    "# Use your cleaned ratings DataFrame (5000 × 100, NaNs where no rating)\n",
    "# Fill NaNs with 0s for SVD input\n",
    "ratings_matrix = ratings.fillna(0).to_numpy()\n",
    "\n",
    "# Perform SVD\n",
    "svd = TruncatedSVD(n_components=20, random_state=42)\n",
    "user_factors = svd.fit_transform(ratings_matrix)\n",
    "item_factors = svd.components_.T  # shape: (100 jokes × 20 latent features)\n",
    "\n",
    "# Choose a user (e.g., user index 10)\n",
    "user_idx = 10\n",
    "user_vector = user_factors[user_idx]\n",
    "\n",
    "# Compute scores and get top recommendations\n",
    "scores = np.dot(item_factors, user_vector)\n",
    "top_items = np.argsort(-scores)[:5]\n",
    "\n",
    "# Novelty — penalize popular jokes\n",
    "item_popularity = np.sum(ratings_matrix > 0, axis=0)\n",
    "item_popularity = item_popularity / item_popularity.max()\n",
    "novelty = np.mean([1 - item_popularity[i] for i in top_items])\n",
    "\n",
    "# Diversity — average pairwise dissimilarity among recommended items\n",
    "item_vecs = item_factors[top_items]\n",
    "sim_matrix = cosine_similarity(item_vecs)\n",
    "upper_triangle = sim_matrix[np.triu_indices(len(top_items), k=1)]\n",
    "diversity = 1 - np.mean(upper_triangle)\n",
    "\n",
    "# Serendipity — dissimilarity from user's past highly rated jokes\n",
    "liked_items = np.where(ratings_matrix[user_idx] >= 4)[0]\n",
    "liked_vecs = item_factors[liked_items]\n",
    "serendipity_scores = []\n",
    "\n",
    "for i in top_items:\n",
    "    rec_vec = item_factors[i].reshape(1, -1)\n",
    "    if liked_vecs.shape[0] > 0:\n",
    "        sim = cosine_similarity(rec_vec, liked_vecs)\n",
    "        serendipity_scores.append(1 - np.mean(sim))\n",
    "\n",
    "serendipity = np.mean(serendipity_scores)\n",
    "\n",
    "# Print results\n",
    "print(f\"Top recommended joke indices for user {user_idx}: {top_items}\")\n",
    "print(f\"Novelty: {novelty:.4f}\")\n",
    "print(f\"Diversity: {diversity:.4f}\")\n",
    "print(f\"Serendipity: {serendipity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a972214e",
   "metadata": {},
   "source": [
    "USING A DIFFERENT METHOND TO COME TO THE SAME CONCLUSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b8677620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommended joke indices for user 10: [49 34 28 26 35]\n",
      "Novelty: 0.0522\n",
      "Diversity: 0.5275\n",
      "Serendipity: 0.7622\n",
      "\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Prepare rating matrix (5000 × 100, fill NaNs with 0)\n",
    "ratings_matrix = ratings.fillna(0).to_numpy()\n",
    "\n",
    "# Perform full SVD: A = U × Σ × V^T\n",
    "U, S, VT = np.linalg.svd(ratings_matrix, full_matrices=False)\n",
    "\n",
    "# Use top 20 latent dimensions (truncate manually)\n",
    "k = 20\n",
    "U_k = U[:, :k]\n",
    "S_k = np.diag(S[:k])\n",
    "VT_k = VT[:k, :]\n",
    "\n",
    "# User and item latent factors\n",
    "user_factors = np.dot(U_k, S_k)           # shape: (5000, 20)\n",
    "item_factors = VT_k.T                     # shape: (100, 20)\n",
    "\n",
    "# Choose a user (e.g., user index 10)\n",
    "user_idx = 10\n",
    "user_vector = user_factors[user_idx]\n",
    "\n",
    "# Compute recommendation scores\n",
    "scores = np.dot(item_factors, user_vector)\n",
    "top_items = np.argsort(-scores)[:5]\n",
    "\n",
    "#Novelty — penalize popular jokes\n",
    "item_popularity = np.sum(ratings_matrix > 0, axis=0)\n",
    "item_popularity = item_popularity / item_popularity.max()\n",
    "novelty = np.mean([1 - item_popularity[i] for i in top_items])\n",
    "\n",
    "#Diversity — pairwise dissimilarity\n",
    "item_vecs = item_factors[top_items]\n",
    "sim_matrix = cosine_similarity(item_vecs)\n",
    "upper_triangle = sim_matrix[np.triu_indices(len(top_items), k=1)]\n",
    "diversity = 1 - np.mean(upper_triangle)\n",
    "\n",
    "# Serendipity — difference from user's liked items\n",
    "liked_items = np.where(ratings_matrix[user_idx] >= 4)[0]\n",
    "liked_vecs = item_factors[liked_items]\n",
    "serendipity_scores = []\n",
    "\n",
    "for i in top_items:\n",
    "    rec_vec = item_factors[i].reshape(1, -1)\n",
    "    if liked_vecs.shape[0] > 0:\n",
    "        sim = cosine_similarity(rec_vec, liked_vecs)\n",
    "        serendipity_scores.append(1 - np.mean(sim))\n",
    "\n",
    "serendipity = np.mean(serendipity_scores)\n",
    "\n",
    "# Print results\n",
    "print(f\"Top recommended joke indices for user {user_idx}: {top_items}\")\n",
    "print(f\"Novelty: {novelty:.4f}\")\n",
    "print(f\"Diversity: {diversity:.4f}\")\n",
    "print(f\"Serendipity: {serendipity:.4f}\")\n",
    "print(\"\\n\" + \"=\"*100 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16cd941",
   "metadata": {},
   "source": [
    "CREATED A FULL SIGMA MATRIX FOR VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "04a869c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Σ Matrix- Shape: (100, 100)\n",
      "[[1552.449    0.       0.    ...    0.       0.       0.   ]\n",
      " [   0.     969.155    0.    ...    0.       0.       0.   ]\n",
      " [   0.       0.     587.591 ...    0.       0.       0.   ]\n",
      " ...\n",
      " [   0.       0.       0.    ...  143.081    0.       0.   ]\n",
      " [   0.       0.       0.    ...    0.     141.113    0.   ]\n",
      " [   0.       0.       0.    ...    0.       0.     138.204]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    " Sigma = np.zeros((U.shape[1], VT.shape[0]))\n",
    " np.fill_diagonal(Sigma, S)\n",
    " print(f\"Full Σ Matrix- Shape: {Sigma.shape}\")\n",
    " print(np.round(Sigma, 3))\n",
    " print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "74d1cd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Singular Values in diagonal matrix (S):\n",
      "S matrix shape: (100,)\n",
      "1552.449\n",
      "969.155\n",
      "587.591\n",
      "529.908\n",
      "509.484\n",
      "460.013\n",
      "393.820\n",
      "389.366\n",
      "386.568\n",
      "361.107\n",
      "352.189\n",
      "337.462\n",
      "323.402\n",
      "321.424\n",
      "314.707\n",
      "313.201\n",
      "308.663\n",
      "307.531\n",
      "300.760\n",
      "297.792\n",
      "288.939\n",
      "286.671\n",
      "282.573\n",
      "280.126\n",
      "276.898\n",
      "276.256\n",
      "274.732\n",
      "270.584\n",
      "268.983\n",
      "266.879\n",
      "265.634\n",
      "262.646\n",
      "261.934\n",
      "257.492\n",
      "255.792\n",
      "254.205\n",
      "253.366\n",
      "251.504\n",
      "250.381\n",
      "249.723\n",
      "248.589\n",
      "246.992\n",
      "244.892\n",
      "244.177\n",
      "242.719\n",
      "241.431\n",
      "239.193\n",
      "238.084\n",
      "237.478\n",
      "235.947\n",
      "235.489\n",
      "232.931\n",
      "231.984\n",
      "230.416\n",
      "230.093\n",
      "227.444\n",
      "226.206\n",
      "224.841\n",
      "223.659\n",
      "222.036\n",
      "221.522\n",
      "220.072\n",
      "218.944\n",
      "218.132\n",
      "216.879\n",
      "215.865\n",
      "213.824\n",
      "212.023\n",
      "210.630\n",
      "208.713\n",
      "206.463\n",
      "206.354\n",
      "202.978\n",
      "201.048\n",
      "197.512\n",
      "195.401\n",
      "194.228\n",
      "191.231\n",
      "189.698\n",
      "187.871\n",
      "184.242\n",
      "183.609\n",
      "180.676\n",
      "178.291\n",
      "175.276\n",
      "170.739\n",
      "169.200\n",
      "166.882\n",
      "164.177\n",
      "162.764\n",
      "161.031\n",
      "158.233\n",
      "157.063\n",
      "151.580\n",
      "150.731\n",
      "149.332\n",
      "146.968\n",
      "143.081\n",
      "141.113\n",
      "138.204\n",
      "\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSingular Values in diagonal matrix (S):\")\n",
    "print(f\"S matrix shape: {S.shape}\")\n",
    "for val in S:\n",
    "    print(f\"{val:.3f}\")\n",
    "print(\"\\n\" + \"=\"*100 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76932964",
   "metadata": {},
   "source": [
    "VARIANCE\n",
    "\n",
    "This helped me determine the optimal number of principal components to retain in a dataset.\n",
    " By observing the point where the cumulative explained variance starts to level off (often referred to as an \"elbow\"), 10 components are needed to capture a sufficient amount of the data's variability while reducing dimensionality.\n",
    "variance in accuracy refers to how much the performance of the system (measured by accuracy metrics) changes when trained on different subsets of the data. \n",
    "The variable represented on the x-axis of the graph is k, which stands for the number of principal components. \n",
    "In the context of Principal Component Analysis (PCA) and a cumulative explained variance plot, k represents the number of principal components included in the analysis. The plot shows how the cumulative variance explained increases as you include more principal components. \n",
    "This helped me determine the optimal number of principal components to retain in a dataset as 20. By observing the point where the cumulative explained variance starts to level off (often referred to as an \"elbow\"), analysts can decide how many components are needed to capture a sufficient amount of the data's variability while reducing dimensionality. \n",
    "AT k = 10 Energy retained was 50%\n",
    "AT k = 30 Energy retained was 68%\n",
    "AT k = 50 Energy retained was 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ecb9ddb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "explained_variance = (S**2) / np.sum(S**2)\n",
    "cumulative = np.cumsum(explained_variance)\n",
    "\n",
    "plt.plot(range(1, 51), cumulative[:50], marker='o')\n",
    "plt.title('Cumulative Variance Explained (Top 50 Components)')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Cumulative Variance')\n",
    "plt.axhline(y=0.90, color='r', linestyle='--')  # 90% threshold\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e4647583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U_reduced shape: (5000, 20)\n",
      "sigma_reduced shape: (20, 20)\n",
      "Vt_reduced shape: (20, 100)\n",
      "\n",
      "Ranking reveals the underlying structure and simplifies data representation\n",
      "\n",
      "Rank-20 Approximation (first 5 users × first 5 jokes):\n",
      "        joke_1  joke_2  joke_3  joke_4  joke_5\n",
      "user_0   -3.71   -0.91   -6.21   -8.89   -6.72\n",
      "user_1    2.72    1.56    6.76    7.51   -0.70\n",
      "user_2    0.88    2.87   -0.20    0.07    8.08\n",
      "user_3    1.01    4.56    2.33    1.48    2.25\n",
      "user_4    3.30    5.81    1.85   -1.41    1.74\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Reduce rank to k = 20\n",
    "k = 20\n",
    "U_reduced = U[:, :k]                         # (5000 × 20)\n",
    "sigma_reduced = np.diag(S[:k])              # (20 × 20)\n",
    "Vt_reduced = VT[:k, :]                       # (20 × 100)\n",
    "\n",
    "print(f\"U_reduced shape: {U_reduced.shape}\")\n",
    "print(f\"sigma_reduced shape: {sigma_reduced.shape}\")\n",
    "print(f\"Vt_reduced shape: {Vt_reduced.shape}\")\n",
    "\n",
    "# Reconstruct matrix using rank-2 approximation\n",
    "approximated = U_reduced @ sigma_reduced @ Vt_reduced  # shape: (5000 × 100)\n",
    "\n",
    "# Display a small sample of approximated values\n",
    "print(\"\\nRanking reveals the underlying structure and simplifies data representation\")\n",
    "print(\"\\nRank-20 Approximation (first 5 users × first 5 jokes):\")\n",
    "joke_columns = [f'joke_{i}' for i in range(1, 100)]\n",
    "df_approx = pd.DataFrame(np.round(approximated[:5, :5], 2),\n",
    "                         index=[f'user_{i}' for i in range(5)],\n",
    "                         columns=joke_columns[:5])\n",
    "print(df_approx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "83b8f029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Approximation error (lower = better approximation): 1978.790\n",
      "\n",
      "Singular values kept (top 20): [[1552.449    0.       0.    ...    0.       0.       0.   ]\n",
      " [   0.     969.155    0.    ...    0.       0.       0.   ]\n",
      " [   0.       0.     587.591 ...    0.       0.       0.   ]\n",
      " ...\n",
      " [   0.       0.       0.    ...    0.       0.       0.   ]\n",
      " [   0.       0.       0.    ...    0.       0.       0.   ]\n",
      " [   0.       0.       0.    ...    0.       0.       0.   ]]\n",
      "Singular values discarded: [[  0.      0.      0.    ...   0.      0.      0.   ]\n",
      " [  0.      0.      0.    ...   0.      0.      0.   ]\n",
      " [  0.      0.      0.    ...   0.      0.      0.   ]\n",
      " ...\n",
      " [  0.      0.      0.    ... 143.081   0.      0.   ]\n",
      " [  0.      0.      0.    ...   0.    141.113   0.   ]\n",
      " [  0.      0.      0.    ...   0.      0.    138.204]]\n",
      "Energy retained: 60.7%\n",
      "\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compute approximation error (Frobenius norm)\n",
    "approximation_error = np.linalg.norm(ratings_matrix - approximated)\n",
    "\n",
    "# Show summary\n",
    "print(f\"\\nApproximation error (lower = better approximation): {approximation_error:.3f}\")\n",
    "\n",
    "print(f\"\\nSingular values kept (top {k}): {np.round(Sigma[:k], 3)}\")\n",
    "print(f\"Singular values discarded: {np.round(Sigma[k:], 3)}\")\n",
    "\n",
    "# Energy retained\n",
    "energy_retained = np.sum(Sigma[:k]**2) / np.sum(Sigma**2)\n",
    "print(f\"Energy retained: {energy_retained:.1%}\")\n",
    "print(\"\\n\" + \"=\"*100 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24712e27",
   "metadata": {},
   "source": [
    "\n",
    "RMSE, MAE RMSE and  MSE \n",
    "\n",
    "\n",
    "SVD, UBCF, and IBCF are designed to learn complex patterns and relationships within the data, going beyond simple averages. \n",
    "This allows them to make more personalized and potentially more accurate predictions, leading to lower RMSE and MAE values compared to the Global Baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "652c01db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Baseline Recommender Results:\n",
      "RMSE: 4.329\n",
      "MAE: 3.453\n"
     ]
    }
   ],
   "source": [
    "ratings.columns = ['ratingCount'] + [f'joke_{i}' for i in range(1, 100)]\n",
    "ratings = ratings.drop(columns=['ratingCount'])\n",
    "ratings.replace(99, np.nan, inplace=True)\n",
    "ratings = ratings.iloc[:5000]  # first 5000 users\n",
    "\n",
    "# Step 2: Convert to long format\n",
    "ratings_long = ratings.reset_index().melt(id_vars='index', var_name='item_id', value_name='rating')\n",
    "ratings_long.columns = ['user_id', 'item_id', 'rating']\n",
    "ratings_long.dropna(inplace=True)\n",
    "ratings_long['user_id'] = ratings_long['user_id'].apply(lambda x: f'u{x}')\n",
    "ratings_long['item_id'] = ratings_long['item_id'].apply(lambda x: f'j{int(x.split(\"_\")[1])}')\n",
    "\n",
    "# Step 3: Faster Global Baseline Recommender\n",
    "class FastGlobalBaseline:\n",
    "    def __init__(self, reg_user=5.0, reg_item=5.0):\n",
    "        self.reg_user = reg_user\n",
    "        self.reg_item = reg_item\n",
    "\n",
    "    def fit(self, df):\n",
    "        self.mu = df['rating'].mean()\n",
    "\n",
    "        # Compute user bias\n",
    "        user_sum = df.groupby('user_id')['rating'].sum()\n",
    "        user_count = df.groupby('user_id')['rating'].count()\n",
    "        self.bu = ((user_sum - user_count * self.mu) / (user_count + self.reg_user)).to_dict()\n",
    "\n",
    "        # Adjusted ratings for item bias\n",
    "        df['adj_rating'] = df.apply(lambda row: row['rating'] - self.mu - self.bu.get(row['user_id'], 0), axis=1)\n",
    "        item_sum = df.groupby('item_id')['adj_rating'].sum()\n",
    "        item_count = df.groupby('item_id')['adj_rating'].count()\n",
    "        self.bi = (item_sum / (item_count + self.reg_item)).to_dict()\n",
    "\n",
    "    def predict(self, user_id, item_id):\n",
    "        return max(-10, min(10, self.mu + self.bu.get(user_id, 0) + self.bi.get(item_id, 0)))\n",
    "\n",
    "    def predict_batch(self, user_item_pairs):\n",
    "        return [self.predict(u, i) for u, i in user_item_pairs]\n",
    "\n",
    "# Step 4: Train/test split and evaluate\n",
    "train_data, test_data = train_test_split(ratings_long, test_size=0.2, random_state=42)\n",
    "\n",
    "model = FastGlobalBaseline()\n",
    "model.fit(train_data)\n",
    "\n",
    "# Predict\n",
    "test_data['predicted'] = model.predict_batch(list(zip(test_data['user_id'], test_data['item_id'])))\n",
    "\n",
    "# Evaluate\n",
    "rmse = np.sqrt(mean_squared_error(test_data['rating'], test_data['predicted']))\n",
    "mae = np.mean(np.abs(test_data['rating'] - test_data['predicted']))\n",
    "\n",
    "print(f\"Global Baseline Recommender Results:\")\n",
    "print(f\"RMSE: {rmse:.3f}\")\n",
    "print(f\"MAE: {mae:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb8db12",
   "metadata": {},
   "source": [
    "RECOMMENDER MODELS\n",
    "\n",
    "\n",
    "The lower RMSE and MAE values for SVD, UBCF, and IBCF indicate that these models are generally more effective at capturing the underlying patterns in the data and making more accurate predictions compared to the simpler Global Baseline Recommender. \n",
    "SVD has the lowest RMSE (3.214) and MAE (2.421).\n",
    "Lower RMSE and MAE values indicate better accuracy because they represent the average prediction error, with smaller numbers indicating less error.\n",
    "While UBCF and IBCF are collaborative filtering methods, SVD is a matrix factorization technique that excels at predicting user preferences by identifying latent factors.\n",
    "In this specific comparison based on the provided metrics, SVD demonstrates superior performance in terms of accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1bb4cd65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model   RMSE     MSE    MAE\n",
      "0   SVD  3.206  10.279  2.418\n",
      "1  UBCF  3.880  15.058  3.061\n",
      "2  IBCF  4.251  18.069  3.395\n"
     ]
    }
   ],
   "source": [
    "# Fill NaNs temporarily with zeros for SVD input\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "ratings_filled = pd.DataFrame(imputer.fit_transform(ratings), columns=ratings.columns)\n",
    "\n",
    "# Mask of known ratings\n",
    "mask = ~ratings.isna()\n",
    "true_values = ratings[mask]\n",
    "\n",
    "def evaluate(preds, truth_mask):\n",
    "    y_true = truth_mask.values.flatten()\n",
    "    y_pred = preds.values.flatten()\n",
    "    mask_flat = ~np.isnan(y_true)\n",
    "    return {\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(y_true[mask_flat], y_pred[mask_flat])),\n",
    "        \"MSE\": mean_squared_error(y_true[mask_flat], y_pred[mask_flat]),\n",
    "        \"MAE\": mean_absolute_error(y_true[mask_flat], y_pred[mask_flat])\n",
    "    }\n",
    "\n",
    "# --- SVD (no change) ---\n",
    "svd = TruncatedSVD(n_components=20, random_state=42)\n",
    "svd_user_factors = svd.fit_transform(ratings_filled)\n",
    "svd_item_factors = svd.components_.T\n",
    "svd_preds = pd.DataFrame(np.dot(svd_user_factors, svd_item_factors.T), columns=ratings.columns)\n",
    "svd_metrics = evaluate(svd_preds, true_values)\n",
    "\n",
    "# --- UBCF with user mean normalization ---\n",
    "user_means = ratings.mean(axis=1)\n",
    "ratings_centered = ratings.subtract(user_means, axis=0).fillna(0)\n",
    "\n",
    "user_sim = cosine_similarity(ratings_centered)\n",
    "np.fill_diagonal(user_sim, 0)\n",
    "\n",
    "# Weighted sum predictions\n",
    "weighted_sum = np.dot(user_sim, ratings_centered)\n",
    "sim_sums = np.abs(user_sim).sum(axis=1)[:, None]\n",
    "sim_sums[sim_sums == 0] = 1e-8  # avoid div by zero\n",
    "\n",
    "ubcf_preds_centered = weighted_sum / sim_sums\n",
    "# Add back user means\n",
    "ubcf_preds = pd.DataFrame(ubcf_preds_centered, columns=ratings.columns).add(user_means, axis=0)\n",
    "\n",
    "ubcf_metrics = evaluate(ubcf_preds, true_values)\n",
    "\n",
    "# --- IBCF with item mean normalization ---\n",
    "item_means = ratings.mean(axis=0)\n",
    "ratings_centered_item = ratings.subtract(item_means, axis=1).fillna(0)\n",
    "\n",
    "item_sim = cosine_similarity(ratings_centered_item.T)\n",
    "np.fill_diagonal(item_sim, 0)\n",
    "\n",
    "weighted_sum_item = np.dot(ratings_centered_item, item_sim)\n",
    "sim_sums_item = np.abs(item_sim).sum(axis=1)\n",
    "sim_sums_item[sim_sums_item == 0] = 1e-8\n",
    "\n",
    "ibcf_preds_centered = weighted_sum_item / sim_sums_item\n",
    "ibcf_preds = pd.DataFrame(ibcf_preds_centered, columns=ratings.columns).add(item_means, axis=1)\n",
    "\n",
    "ibcf_metrics = evaluate(ibcf_preds, true_values)\n",
    "# --- Results ---\n",
    "results = pd.DataFrame([\n",
    "    {\"Model\": \"SVD\", **svd_metrics},\n",
    "    {\"Model\": \"UBCF\", **ubcf_metrics},\n",
    "    {\"Model\": \"IBCF\", **ibcf_metrics}\n",
    "])\n",
    "\n",
    "print(results.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac7413f",
   "metadata": {},
   "source": [
    "\n",
    "MODEL TIME AND PREDICTION TIME COMPARISON\n",
    "\n",
    "\n",
    "SVD has a low model time (0.033 sec) and very low prediction time (0.000 sec), indicating that once the SVD model is trained, it can generate predictions very quickly.\n",
    "UBCF with highest model time of (0.097 sec) and also the highest prediction time (0.131 sec), suggests that UBCF might be less efficient in both building the model and generating recommendations compared to SVD and IBCF.\n",
    "IBCF have a very low model time (0.010 sec) and a low prediction time (0.004 sec) it appears to be quite efficient in both model training and prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "25ee8974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD run fold/sample [model time/prediction time]\n",
      " 1  [0.020sec/0.001sec]\n",
      "UBCF run fold/sample [model time/prediction time]\n",
      " 1  [0.090sec/0.128sec]\n",
      "IBCF run fold/sample [model time/prediction time]\n",
      " 1  [0.003sec/0.005sec]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "ratings_filled = pd.DataFrame(imputer.fit_transform(ratings), columns=ratings.columns)\n",
    "\n",
    "start_model = time.time()\n",
    "svd = TruncatedSVD(n_components=20, random_state=42)\n",
    "user_factors = svd.fit_transform(ratings_filled)\n",
    "item_factors = svd.components_.T\n",
    "end_model = time.time()\n",
    "\n",
    "start_pred = time.time()\n",
    "svd_preds = pd.DataFrame(np.dot(user_factors, item_factors.T), columns=ratings.columns)\n",
    "end_pred = time.time()\n",
    "\n",
    "print(f\"SVD run fold/sample [model time/prediction time]\\n 1  [{end_model - start_model:.3f}sec/{end_pred - start_pred:.3f}sec]\")\n",
    "\n",
    "# --- UBCF ---\n",
    "user_means = ratings.mean(axis=1)\n",
    "ratings_centered = ratings.subtract(user_means, axis=0).fillna(0)\n",
    "\n",
    "start_model = time.time()\n",
    "user_sim = cosine_similarity(ratings_centered)\n",
    "np.fill_diagonal(user_sim, 0)\n",
    "end_model = time.time()\n",
    "\n",
    "start_pred = time.time()\n",
    "weighted_sum = np.dot(user_sim, ratings_centered)\n",
    "sim_sums = np.abs(user_sim).sum(axis=1)[:, None]\n",
    "sim_sums[sim_sums == 0] = 1e-8\n",
    "ubcf_preds_centered = weighted_sum / sim_sums\n",
    "ubcf_preds = pd.DataFrame(ubcf_preds_centered, columns=ratings.columns).add(user_means, axis=0)\n",
    "end_pred = time.time()\n",
    "\n",
    "print(f\"UBCF run fold/sample [model time/prediction time]\\n 1  [{end_model - start_model:.3f}sec/{end_pred - start_pred:.3f}sec]\")\n",
    "\n",
    "# --- IBCF ---\n",
    "item_means = ratings.mean(axis=0)\n",
    "ratings_centered_item = ratings.subtract(item_means, axis=1).fillna(0)\n",
    "\n",
    "start_model = time.time()\n",
    "item_sim = cosine_similarity(ratings_centered_item.T)\n",
    "np.fill_diagonal(item_sim, 0)\n",
    "end_model = time.time()\n",
    "\n",
    "start_pred = time.time()\n",
    "weighted_sum_item = np.dot(ratings_centered_item, item_sim)\n",
    "sim_sums_item = np.abs(item_sim).sum(axis=1)\n",
    "sim_sums_item[sim_sums_item == 0] = 1e-8\n",
    "ibcf_preds_centered = weighted_sum_item / sim_sums_item\n",
    "ibcf_preds = pd.DataFrame(ibcf_preds_centered, columns=ratings.columns).add(item_means, axis=1)\n",
    "end_pred = time.time()\n",
    "\n",
    "print(f\"IBCF run fold/sample [model time/prediction time]\\n 1  [{end_model - start_model:.3f}sec/{end_pred - start_pred:.3f}sec]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10061d6",
   "metadata": {},
   "source": [
    "Increase Serendipity\n",
    "\n",
    "SVD2 retains the lowest RMSE and MAE, it is likely the most accurate model for predicting user ratings, based on these metrics.\n",
    "While UBCF2 and IBCF2 may have higher error rates compared to SVD2 in this specific comparison, they might have different strengths in terms of serendipity. Collaborative filtering methods, depending on their implementation, can sometimes be better at surfacing diverse or less popular items, potentially contributing more to serendipity than a pure matrix factorization approach like SVD. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7f6641f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model   RMSE     MSE    MAE\n",
      "0  UBCF2  3.880  15.058  3.061\n",
      "1   SVD2  3.206  10.279  2.418\n",
      "2  IBCF2  4.251  18.069  3.395\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def evaluate(preds, truth_mask):\n",
    "    y_true = truth_mask.values.flatten()\n",
    "    y_pred = preds.values.flatten()\n",
    "    mask_flat = ~np.isnan(y_true)\n",
    "    return {\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(y_true[mask_flat], y_pred[mask_flat])),\n",
    "        \"MSE\": mean_squared_error(y_true[mask_flat], y_pred[mask_flat]),\n",
    "        \"MAE\": mean_absolute_error(y_true[mask_flat], y_pred[mask_flat])\n",
    "    }\n",
    "\n",
    "# Use same ratings DataFrame from earlier\n",
    "true_values = ratings.copy()\n",
    "true_values[true_values == 99] = np.nan\n",
    "\n",
    "# --- SVD2 (base) ---\n",
    "svd2_metrics = evaluate(svd_preds, true_values)\n",
    "\n",
    "# --- UBCF2 ---\n",
    "ubcf2_metrics = evaluate(ubcf_preds, true_values)\n",
    "\n",
    "# --- IBCF2 ---\n",
    "ibcf2_metrics = evaluate(ibcf_preds, true_values)\n",
    "\n",
    "# --- Combine ---\n",
    "results_serendipity = pd.DataFrame([\n",
    "    {\"Model\": \"UBCF2\", **ubcf2_metrics},\n",
    "    {\"Model\": \"SVD2\", **svd2_metrics},\n",
    "    {\"Model\": \"IBCF2\", **ibcf2_metrics}\n",
    "])\n",
    "\n",
    "print(results_serendipity.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379775dc",
   "metadata": {},
   "source": [
    "PRECISION\n",
    "\n",
    "Out of the top 5 items recommended, how many are actually relevant to the user?\" \n",
    "\n",
    "UBCF2 Scores the highest Precision@5 (0.632). This means that for every 5 recommendations it provides, approximately 63.2% of them are relevant to the user.\n",
    "SVD2's slightly lower Precision@5 (0.621), indicates that it's slightly less precise in its top 5 recommendations compared to UBCF2.\n",
    "As for IBCF2 with the lowest Precision@5 (0.409) it suggests that it's the least precise in its top 5 recommendations, with only about 40.9% of them being relevant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b9fafba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Precision@5\n",
      "UBCF2        0.632\n",
      "SVD2         0.621\n",
      "IBCF2        0.409\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def precision_at_k(preds, truth, k=5, threshold=5.0):\n",
    "    precisions = []\n",
    "    \n",
    "    for user_idx in range(len(truth)):\n",
    "        true_ratings = truth.iloc[user_idx]\n",
    "        pred_ratings = preds.iloc[user_idx]\n",
    "\n",
    "        # Only consider items the user has rated\n",
    "        known_items = true_ratings[~true_ratings.isna()]\n",
    "\n",
    "        # Get top-K predictions for those known items\n",
    "        top_k_items = pred_ratings[known_items.index].sort_values(ascending=False).head(k)\n",
    "\n",
    "        # Count how many of the top K were actually relevant\n",
    "        actual_relevant = true_ratings[top_k_items.index] >= threshold\n",
    "        precision = actual_relevant.sum() / k\n",
    "        precisions.append(precision)\n",
    "\n",
    "    return np.mean(precisions)\n",
    "p_at_5 = {\n",
    "    \"UBCF2\": precision_at_k(ubcf_preds, true_values, k=5),\n",
    "    \"SVD2\": precision_at_k(svd_preds, true_values, k=5),\n",
    "    \"IBCF2\": precision_at_k(ibcf_preds, true_values, k=5)\n",
    "}\n",
    "print(pd.DataFrame.from_dict(p_at_5, orient='index', columns=['Precision@5']).round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc24fc8",
   "metadata": {},
   "source": [
    "CONCLUSION\n",
    "\n",
    "Recommender systems can be evaluated offline or online. The purpose of recommender system evaluation is to select algorithms for use in a production setting.\n",
    "\n",
    "Offline evaluation test the effectiveness of recommender system algorithms on a certain dataset. To measure accuracy, precision at position n (P@n) is often used to express how many items of the ground-truth are recommended within the top n recommendations. The purpose of offline evaluation is to select recommender systems for deployment online. Offline evaluations are easier and reproducible.\n",
    "\n",
    "Online evaluation occurs after you've deployed your model to production and are serving end-users with results from your algorithm. \n",
    "Typically when first deploying a new algorithm to production, you'll run an A/B test where you serve the new algorithm to a subset of users and compare the results to a control group that's served the old algorithm.\n",
    "\n",
    "Multi-armed bandit testing is a sophisticated approach to model evaluation that dynamically allocates traffic to different models based on their performance. This method balances the need for exploration (trying out different models) and exploitation (favoring the best-performing models).\n",
    "\n",
    "Interleaving is another technique used in online model evaluation where recommendations from different models are presented together to the same users. This can be achieved by interleaving items from different models within the recommendation list.\n",
    "\n",
    "\n",
    "References:\n",
    "Hijikata, Y. Offline Evaluation for Recommender Systems. http://soc-research.org/wp-content/uploads/2014/11/OfflineTest4RS.pdf\n",
    "\n",
    "Gebrekirstos G., et. al. Recommender Systems Evaluations: Offline, Online, Time and A/A Test http://ceur-ws.org/Vol-1609/16090642.pdf\n",
    "\n",
    "https://www.shaped.ai/blog/evaluating-recommender-models-offline-vs-online-evaluation\n",
    "\n",
    "Data source\n",
    "\n",
    "Eigentaste: A Constant Time Collaborative Filtering Algorithm. Ken Goldberg, Theresa Roeder, Dhruv Gupta, and Chris Perkins. Information Retrieval, 4(2), 133-151. July 2001. u."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf38f68d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
